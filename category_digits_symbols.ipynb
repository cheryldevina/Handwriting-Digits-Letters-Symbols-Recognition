{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import pathlib\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from emnist import extract_training_samples, extract_test_samples\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMPORTING AND COLLECTING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 488 images belonging to 4 classes.\n",
      "Found 120 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "x_train_d, y_train_d = extract_training_samples('digits')\n",
    "x_test_d, y_test_d = extract_test_samples('digits')\n",
    "\n",
    "train_data_generator = ImageDataGenerator(rescale=1/255.0, validation_split=0.2)\n",
    "\n",
    "data_dir = pathlib.Path('tanda_baca')\n",
    "train_ds = train_data_generator.flow_from_directory(\n",
    "  data_dir,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  target_size=(28, 28),\n",
    "  class_mode=\"categorical\",\n",
    "  batch_size=1,\n",
    "  color_mode=\"grayscale\")\n",
    "\n",
    "val_ds = train_data_generator.flow_from_directory(\n",
    "  data_dir,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  target_size=(28, 28),\n",
    "  class_mode=\"categorical\",\n",
    "  batch_size=1,\n",
    "  color_mode=\"grayscale\")\n",
    "\n",
    "batch_index = 0\n",
    "x_train_s = []\n",
    "y_train_s = []\n",
    "while batch_index <= train_ds.batch_index:\n",
    "    data = train_ds.next()\n",
    "    x_train_s.append(data[0])\n",
    "    y_train_s.append(1)\n",
    "    batch_index += 1\n",
    "    \n",
    "batch_index = 0\n",
    "x_test_s = []\n",
    "y_test_s = []\n",
    "while batch_index <= val_ds.batch_index:\n",
    "    data = val_ds.next()\n",
    "    x_test_s.append(data[0])\n",
    "    y_test_s.append(1)\n",
    "    batch_index += 1\n",
    "    \n",
    "x_train_s, x_test_s = np.array(x_train_s), np.array(x_test_s)\n",
    "y_train_s, y_test_s = np.array(y_train_s), np.array(y_test_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_s.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ADDING IMAGE CHANNEL DIMENSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_s = x_train_s.reshape(x_train_s.shape[0], 28, 28, 1)\n",
    "x_test_s = x_test_s.reshape(x_test_s.shape[0], 28, 28, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({8: 24000,\n",
       "         9: 24000,\n",
       "         6: 24000,\n",
       "         3: 24000,\n",
       "         7: 24000,\n",
       "         1: 24000,\n",
       "         0: 24000,\n",
       "         4: 24000,\n",
       "         5: 24000,\n",
       "         2: 24000})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_train_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SHUFFLING DIGIT DATASET AND SPLITTING FOR BALANCING PURPOSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = [x for x in range(len(y_train_d))]\n",
    "np.random.shuffle(idx)\n",
    "\n",
    "idx_test = [x for x in range(len(y_test_d))]\n",
    "np.random.shuffle(idx_test)\n",
    "\n",
    "y_train_d_new, y_test_d_new = np.array([0 for x in y_train_d]), np.array([0 for x in y_test_d])\n",
    "y_train_s_new, y_test_s_new = np.array([1 for x in y_train_s]), np.array([1 for x in y_test_s])\n",
    "\n",
    "split_x_train_d, split_y_train_d = x_train_d[idx[:488]], y_train_d_new[idx[:488]]\n",
    "split_x_test_d, split_y_test_d = x_test_d[idx_test[:120]], y_test_d_new[idx_test[:120]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ADDING LAST DIMENSION AND NORMALIZING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_x_train_d, split_x_test_d = split_x_train_d.reshape(split_x_train_d.shape[0], 28, 28, 1), split_x_test_d.reshape(split_x_test_d.shape[0], 28, 28, 1)\n",
    "split_x_train_d, split_x_test_d = split_x_train_d/255.0, split_x_test_d/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### COMBINING DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "comb_x_train = np.concatenate((x_train_s, split_x_train_d), axis=0)\n",
    "comb_y_train = np.concatenate((y_train_s_new, split_y_train_d), axis=0)\n",
    "\n",
    "comb_x_test = np.concatenate((x_test_s, split_x_test_d), axis=0)\n",
    "comb_y_test = np.concatenate((y_test_s_new, split_y_test_d), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comb_y_test[68]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MODEL BUILDING & TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 32)        9248      \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 3872)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 32)                123936    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 133,537\n",
      "Trainable params: 133,537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), input_shape=comb_x_train.shape[1:], activation=\"relu\"),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(32, (3, 3), activation=\"relu\"),\n",
    "    Flatten(),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')])\n",
    "\n",
    "model.compile(optimizer = \"adam\", loss=\"binary_crossentropy\", metrics=[\"acc\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "31/31 [==============================] - 3s 10ms/step - loss: 0.1604 - acc: 0.9529 - val_loss: 2.7761e-04 - val_acc: 1.0000\n",
      "Epoch 2/20\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 9.0807e-04 - acc: 1.0000 - val_loss: 4.6789e-06 - val_acc: 1.0000\n",
      "Epoch 3/20\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.1588e-04 - acc: 1.0000 - val_loss: 1.8560e-06 - val_acc: 1.0000\n",
      "Epoch 4/20\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 7.6046e-05 - acc: 1.0000 - val_loss: 1.2003e-06 - val_acc: 1.0000\n",
      "Epoch 5/20\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 2.9920e-04 - acc: 1.0000 - val_loss: 6.8823e-07 - val_acc: 1.0000\n",
      "Epoch 6/20\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 8.7695e-05 - acc: 1.0000 - val_loss: 4.5575e-07 - val_acc: 1.0000\n",
      "Epoch 7/20\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 7.8745e-04 - acc: 1.0000 - val_loss: 6.2608e-04 - val_acc: 1.0000\n",
      "Epoch 8/20\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0016 - acc: 1.0000 - val_loss: 6.3103e-06 - val_acc: 1.0000\n",
      "Epoch 9/20\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.1695e-04 - acc: 1.0000 - val_loss: 1.8156e-05 - val_acc: 1.0000\n",
      "Epoch 10/20\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 2.2781e-04 - acc: 1.0000 - val_loss: 2.6048e-06 - val_acc: 1.0000\n",
      "Epoch 11/20\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 1.3180e-04 - acc: 1.0000 - val_loss: 8.3310e-07 - val_acc: 1.0000\n",
      "Epoch 12/20\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 4.9885e-05 - acc: 1.0000 - val_loss: 7.5481e-07 - val_acc: 1.0000\n",
      "Epoch 13/20\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 6.4440e-05 - acc: 1.0000 - val_loss: 4.6945e-07 - val_acc: 1.0000\n",
      "Epoch 14/20\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 3.6880e-05 - acc: 1.0000 - val_loss: 4.3919e-07 - val_acc: 1.0000\n",
      "Epoch 15/20\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 8.5823e-06 - acc: 1.0000 - val_loss: 4.7301e-07 - val_acc: 1.0000\n",
      "Epoch 16/20\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 7.6737e-04 - acc: 0.9990 - val_loss: 5.0911e-07 - val_acc: 1.0000\n",
      "Epoch 17/20\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 4.2759e-05 - acc: 1.0000 - val_loss: 5.0564e-07 - val_acc: 1.0000\n",
      "Epoch 18/20\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 9.5112e-05 - acc: 1.0000 - val_loss: 6.2917e-07 - val_acc: 1.0000\n",
      "Epoch 19/20\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 1.0144e-04 - acc: 1.0000 - val_loss: 1.3783e-07 - val_acc: 1.0000\n",
      "Epoch 20/20\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 8.0297e-06 - acc: 1.0000 - val_loss: 1.2262e-07 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x249404df3a0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(comb_x_train, comb_y_train, epochs=20, validation_data=(comb_x_test, comb_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 488, 0: 488})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "Counter(comb_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 87ms/step\n",
      "[[1.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x24c2f9a2d10>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = model.predict(np.array(comb_x_test[68]).reshape(1, 28, 28, 1))\n",
    "print(np.round(res))\n",
    "\n",
    "plt.imshow(np.array(comb_x_test[68]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model\\digit_symb.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "afb734500600fd355917ca529030176ea0ca205570884b88f2f6f7d791fd3fbe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
